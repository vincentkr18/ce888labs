{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to machine learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the [scikit-learn documentation](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the 'breast cancer' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn comes with a few standard datasets, for instance the iris and digits datasets for classification and the Boston house prices dataset for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the `.data` member, which is a `n_samples` by `n_features` array. In the case of supervised problem, one or more response variables are stored in the `.target` member.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 features in this dataset\n",
      "The features are: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "n_features = len(cancer.feature_names)\n",
    "print(\"There are %d features in this dataset\" % n_features)\n",
    "print(\"The features are:\", cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in the case of the breast cancer dataset, cancer.data gives access to the features that can be used to classify the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data.shape)\n",
    "print(cancer.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and `cancer.target` gives the ground truth for the dataset, that is whether the tumor is benign or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target.shape)\n",
    "print(cancer.target)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your chance to have a look at the data. Try some of the things from the seaborn/pandas lab session. What's easier for you, to work with this sort of dataset or with a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(cancer.data[:, 0], cancer.data[:, 1])\n",
    "plt.xlabel(cancer.feature_names[0])\n",
    "plt.ylabel(cancer.feature_names[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your own code visualization/analysis here.\n",
    "# Try to come up with a method that you can use to determine whether your data requires any sort of standarisation.\n",
    "sns.pairplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning and predicting\n",
    "In the case of the breast cancer dataset, the task is to predict, given some features, whether the tumor is benign or malign. We are given samples of each case, and with these samples we fit an estimator to be able to predict the classes to which unseen samples belong.\n",
    "\n",
    "In scikit-learn, an estimator for classification is a Python object that implements the methods `fit(X, y)` and `predict(T)`.\n",
    "\n",
    "An example of an estimator is the class `sklearn.svm.SVC` that implements support vector classification. The constructor of an estimator takes as arguments the parameters of the model, but for the time being, we will consider the estimator as a black box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma=0.0001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our estimator instance `clf`, as it is a classifier. **It now must be fitted to the model, that is, it must learn from the data**. This is done by passing our training set to the `fit` method. As a training set, let us use all the examples of our dataset except for the last one. We select this training set with the `[:-1]` Python syntax, which produces a new array that contains **all but the last entry** of `cancer.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.76e+00, 2.45e+01, 4.79e+01, 1.81e+02, 5.26e-02, 4.36e-02,\n",
       "        0.00e+00, 0.00e+00, 1.59e-01, 5.88e-02, 3.86e-01, 1.43e+00,\n",
       "        2.55e+00, 1.91e+01, 7.19e-03, 4.66e-03, 0.00e+00, 0.00e+00,\n",
       "        2.68e-02, 2.78e-03, 9.46e+00, 3.04e+01, 5.92e+01, 2.69e+02,\n",
       "        9.00e-02, 6.44e-02, 0.00e+00, 0.00e+00, 2.87e-01, 7.04e-02]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(cancer.data[:-1], cancer.target[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can predict new values, in particular, we can ask to the classifier whether the tumor from the last example is benign or not. **Remember that this patient was NOT used to train the classifier**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual value is [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"The predicted value is\", clf.predict(cancer.data[-1:]))##Insert code here\n",
    "#cancer.data[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check what the real label for this patient was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual value is [1]\n"
     ]
    }
   ],
   "source": [
    "#Insert code here\n",
    "print(\"The actual value is\", cancer.target[-1:].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you print the actual raw values of the 30 features for this patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.05338</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.07682</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>...</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.02076</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>...</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.08632</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>...</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.09170</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.06330</td>\n",
       "      <td>...</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>...</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.08783</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>...</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.07731</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>...</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.16830</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>...</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.09875</td>\n",
       "      <td>0.07953</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.06149</td>\n",
       "      <td>...</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.990         10.38          122.80     1001.0          0.11840   \n",
       "1        20.570         17.77          132.90     1326.0          0.08474   \n",
       "2        19.690         21.25          130.00     1203.0          0.10960   \n",
       "3        11.420         20.38           77.58      386.1          0.14250   \n",
       "4        20.290         14.34          135.10     1297.0          0.10030   \n",
       "5        12.450         15.70           82.57      477.1          0.12780   \n",
       "6        18.250         19.98          119.60     1040.0          0.09463   \n",
       "7        13.710         20.83           90.20      577.9          0.11890   \n",
       "8        13.000         21.82           87.50      519.8          0.12730   \n",
       "9        12.460         24.04           83.97      475.9          0.11860   \n",
       "10       16.020         23.24          102.70      797.8          0.08206   \n",
       "11       15.780         17.89          103.60      781.0          0.09710   \n",
       "12       19.170         24.80          132.40     1123.0          0.09740   \n",
       "13       15.850         23.95          103.70      782.7          0.08401   \n",
       "14       13.730         22.61           93.60      578.3          0.11310   \n",
       "15       14.540         27.54           96.73      658.8          0.11390   \n",
       "16       14.680         20.13           94.74      684.5          0.09867   \n",
       "17       16.130         20.68          108.10      798.8          0.11700   \n",
       "18       19.810         22.15          130.00     1260.0          0.09831   \n",
       "19       13.540         14.36           87.46      566.3          0.09779   \n",
       "20       13.080         15.71           85.63      520.0          0.10750   \n",
       "21        9.504         12.44           60.34      273.9          0.10240   \n",
       "22       15.340         14.26          102.50      704.4          0.10730   \n",
       "23       21.160         23.04          137.20     1404.0          0.09428   \n",
       "24       16.650         21.38          110.00      904.6          0.11210   \n",
       "25       17.140         16.40          116.00      912.7          0.11860   \n",
       "26       14.580         21.53           97.41      644.8          0.10540   \n",
       "27       18.610         20.25          122.10     1094.0          0.09440   \n",
       "28       15.300         25.27          102.40      732.4          0.10820   \n",
       "29       17.570         15.05          115.00      955.1          0.09847   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "1            0.07864         0.08690              0.07017         0.1812   \n",
       "2            0.15990         0.19740              0.12790         0.2069   \n",
       "3            0.28390         0.24140              0.10520         0.2597   \n",
       "4            0.13280         0.19800              0.10430         0.1809   \n",
       "5            0.17000         0.15780              0.08089         0.2087   \n",
       "6            0.10900         0.11270              0.07400         0.1794   \n",
       "7            0.16450         0.09366              0.05985         0.2196   \n",
       "8            0.19320         0.18590              0.09353         0.2350   \n",
       "9            0.23960         0.22730              0.08543         0.2030   \n",
       "10           0.06669         0.03299              0.03323         0.1528   \n",
       "11           0.12920         0.09954              0.06606         0.1842   \n",
       "12           0.24580         0.20650              0.11180         0.2397   \n",
       "13           0.10020         0.09938              0.05364         0.1847   \n",
       "14           0.22930         0.21280              0.08025         0.2069   \n",
       "15           0.15950         0.16390              0.07364         0.2303   \n",
       "16           0.07200         0.07395              0.05259         0.1586   \n",
       "17           0.20220         0.17220              0.10280         0.2164   \n",
       "18           0.10270         0.14790              0.09498         0.1582   \n",
       "19           0.08129         0.06664              0.04781         0.1885   \n",
       "20           0.12700         0.04568              0.03110         0.1967   \n",
       "21           0.06492         0.02956              0.02076         0.1815   \n",
       "22           0.21350         0.20770              0.09756         0.2521   \n",
       "23           0.10220         0.10970              0.08632         0.1769   \n",
       "24           0.14570         0.15250              0.09170         0.1995   \n",
       "25           0.22760         0.22290              0.14010         0.3040   \n",
       "26           0.18680         0.14250              0.08783         0.2252   \n",
       "27           0.10660         0.14900              0.07731         0.1697   \n",
       "28           0.16970         0.16830              0.08751         0.1926   \n",
       "29           0.11570         0.09875              0.07953         0.1739   \n",
       "\n",
       "    mean fractal dimension   ...    worst texture  worst perimeter  \\\n",
       "0                  0.07871   ...            17.33           184.60   \n",
       "1                  0.05667   ...            23.41           158.80   \n",
       "2                  0.05999   ...            25.53           152.50   \n",
       "3                  0.09744   ...            26.50            98.87   \n",
       "4                  0.05883   ...            16.67           152.20   \n",
       "5                  0.07613   ...            23.75           103.40   \n",
       "6                  0.05742   ...            27.66           153.20   \n",
       "7                  0.07451   ...            28.14           110.60   \n",
       "8                  0.07389   ...            30.73           106.20   \n",
       "9                  0.08243   ...            40.68            97.65   \n",
       "10                 0.05697   ...            33.88           123.80   \n",
       "11                 0.06082   ...            27.28           136.50   \n",
       "12                 0.07800   ...            29.94           151.70   \n",
       "13                 0.05338   ...            27.66           112.00   \n",
       "14                 0.07682   ...            32.01           108.80   \n",
       "15                 0.07077   ...            37.13           124.10   \n",
       "16                 0.05922   ...            30.88           123.40   \n",
       "17                 0.07356   ...            31.48           136.80   \n",
       "18                 0.05395   ...            30.88           186.80   \n",
       "19                 0.05766   ...            19.26            99.70   \n",
       "20                 0.06811   ...            20.49            96.09   \n",
       "21                 0.06905   ...            15.66            65.13   \n",
       "22                 0.07032   ...            19.08           125.10   \n",
       "23                 0.05278   ...            35.59           188.00   \n",
       "24                 0.06330   ...            31.56           177.00   \n",
       "25                 0.07413   ...            21.40           152.40   \n",
       "26                 0.06924   ...            33.21           122.40   \n",
       "27                 0.05699   ...            27.26           139.90   \n",
       "28                 0.06540   ...            36.71           149.30   \n",
       "29                 0.06149   ...            19.52           134.90   \n",
       "\n",
       "    worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0       2019.0            0.1622             0.6656          0.71190   \n",
       "1       1956.0            0.1238             0.1866          0.24160   \n",
       "2       1709.0            0.1444             0.4245          0.45040   \n",
       "3        567.7            0.2098             0.8663          0.68690   \n",
       "4       1575.0            0.1374             0.2050          0.40000   \n",
       "5        741.6            0.1791             0.5249          0.53550   \n",
       "6       1606.0            0.1442             0.2576          0.37840   \n",
       "7        897.0            0.1654             0.3682          0.26780   \n",
       "8        739.3            0.1703             0.5401          0.53900   \n",
       "9        711.4            0.1853             1.0580          1.10500   \n",
       "10      1150.0            0.1181             0.1551          0.14590   \n",
       "11      1299.0            0.1396             0.5609          0.39650   \n",
       "12      1332.0            0.1037             0.3903          0.36390   \n",
       "13       876.5            0.1131             0.1924          0.23220   \n",
       "14       697.7            0.1651             0.7725          0.69430   \n",
       "15       943.2            0.1678             0.6577          0.70260   \n",
       "16      1138.0            0.1464             0.1871          0.29140   \n",
       "17      1315.0            0.1789             0.4233          0.47840   \n",
       "18      2398.0            0.1512             0.3150          0.53720   \n",
       "19       711.2            0.1440             0.1773          0.23900   \n",
       "20       630.5            0.1312             0.2776          0.18900   \n",
       "21       314.9            0.1324             0.1148          0.08867   \n",
       "22       980.9            0.1390             0.5954          0.63050   \n",
       "23      2615.0            0.1401             0.2600          0.31550   \n",
       "24      2215.0            0.1805             0.3578          0.46950   \n",
       "25      1461.0            0.1545             0.3949          0.38530   \n",
       "26       896.9            0.1525             0.6643          0.55390   \n",
       "27      1403.0            0.1338             0.2117          0.34460   \n",
       "28      1269.0            0.1641             0.6110          0.63350   \n",
       "29      1227.0            0.1255             0.2812          0.24890   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                0.26540          0.4601                  0.11890       0  \n",
       "1                0.18600          0.2750                  0.08902       0  \n",
       "2                0.24300          0.3613                  0.08758       0  \n",
       "3                0.25750          0.6638                  0.17300       0  \n",
       "4                0.16250          0.2364                  0.07678       0  \n",
       "5                0.17410          0.3985                  0.12440       0  \n",
       "6                0.19320          0.3063                  0.08368       0  \n",
       "7                0.15560          0.3196                  0.11510       0  \n",
       "8                0.20600          0.4378                  0.10720       0  \n",
       "9                0.22100          0.4366                  0.20750       0  \n",
       "10               0.09975          0.2948                  0.08452       0  \n",
       "11               0.18100          0.3792                  0.10480       0  \n",
       "12               0.17670          0.3176                  0.10230       0  \n",
       "13               0.11190          0.2809                  0.06287       0  \n",
       "14               0.22080          0.3596                  0.14310       0  \n",
       "15               0.17120          0.4218                  0.13410       0  \n",
       "16               0.16090          0.3029                  0.08216       0  \n",
       "17               0.20730          0.3706                  0.11420       0  \n",
       "18               0.23880          0.2768                  0.07615       0  \n",
       "19               0.12880          0.2977                  0.07259       1  \n",
       "20               0.07283          0.3184                  0.08183       1  \n",
       "21               0.06227          0.2450                  0.07773       1  \n",
       "22               0.23930          0.4667                  0.09946       0  \n",
       "23               0.20090          0.2822                  0.07526       0  \n",
       "24               0.20950          0.3613                  0.09564       0  \n",
       "25               0.25500          0.4066                  0.10590       0  \n",
       "26               0.27010          0.4264                  0.12750       0  \n",
       "27               0.14900          0.2341                  0.07421       0  \n",
       "28               0.20240          0.4027                  0.09876       0  \n",
       "29               0.14560          0.2756                  0.07919       0  \n",
       "\n",
       "[30 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert code here\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(cancer.data)\n",
    "#df[target]\n",
    "df.columns = cancer.feature_names\n",
    "\n",
    "\n",
    "df['target'] = cancer.target\n",
    "df.head(30)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        t = \"(%.2f)\"%(cm[i, j])\n",
    "        #print t\n",
    "#         plt.text(j, i, t,\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_pred = clf.predict(cancer.data)\n",
    "cnf_matrix = confusion_matrix(cancer.target, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(len(set(cancer.target))), normalize = False,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "#plt.savefig(\"confusion.png\",bbox_inches='tight')\n",
    "#plt.savefig(\"confusion.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common types of errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "**Learning the parameters of a prediction function and testing it on the same data is a methodological mistake**: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called **overfitting**. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set `X_test`, `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.\n",
    "\n",
    "They expose a `split` method which accepts the input dataset to be split and yields the train/test set indices for each iteration of the chosen cross-validation strategy.\n",
    "\n",
    "Let's try with a smaller subset of the `cancer` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31\n",
      " 32 33 34 35 36 37 38 39] | test: [0 1 2 3 4 5 6 7]\n",
      "Fold test accuracy: 100.0 %\n",
      "Train: [ 0  1  2  3  4  5  6  7 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31\n",
      " 32 33 34 35 36 37 38 39] | test: [ 8  9 10 11 12 13 14 15]\n",
      "Fold test accuracy: 87.5 %\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 24 25 26 27 28 29 30 31\n",
      " 32 33 34 35 36 37 38 39] | test: [16 17 18 19 20 21 22 23]\n",
      "Fold test accuracy: 62.5 %\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 32 33 34 35 36 37 38 39] | test: [24 25 26 27 28 29 30 31]\n",
      "Fold test accuracy: 100.0 %\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31] | test: [32 33 34 35 36 37 38 39]\n",
      "Fold test accuracy: 87.5 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "clf = svm.SVC(gamma=0.0001, C=100.)\n",
    "k_fold = KFold(n_splits=5)\n",
    "for train_indices, test_indices in k_fold.split(cancer.data[:40]): # consider the first 40 examples\n",
    "    print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    clf.fit(cancer.data[train_indices], cancer.target[train_indices])\n",
    "    print('Fold test accuracy: {} %'.format(clf.score(cancer.data[test_indices], cancer.target[test_indices])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 94.19486215538848 %\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "clf = svm.SVC(gamma=0.0001, C=100.)\n",
    "k_fold = KFold(n_splits=10)\n",
    "for train_indices, test_indices in k_fold.split(cancer.data):\n",
    "    clf.fit(cancer.data[train_indices], cancer.target[train_indices])\n",
    "    score.append(clf.score(cancer.data[test_indices], cancer.target[test_indices]))\n",
    "print('Average accuracy: {} %'.format(np.mean(score)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a shortcut, we can use `cross_val_score` for the same purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 94.19486215538848 %\n"
     ]
    }
   ],
   "source": [
    "score_2 = cross_val_score(clf, cancer.data, cancer.target, cv=k_fold, n_jobs=-1)\n",
    "print('Average accuracy: {} %'.format(np.mean(score_2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-search\n",
    "\n",
    "Scikit-learn provides an object that, given data, computes the score during the fit of an estimator on a parameter grid and chooses the parameters to maximize the cross-validation score. This object takes an estimator during the construction and exposes an estimator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1000.0 Best gamma: 1e-06 Fold test accuracy: 0.8859649122807017\n",
      "Best C: 1000.0 Best gamma: 1e-06 Fold test accuracy: 0.9649122807017544\n",
      "Best C: 1000.0 Best gamma: 1e-05 Fold test accuracy: 0.9736842105263158\n",
      "Best C: 1000.0 Best gamma: 1e-05 Fold test accuracy: 0.9736842105263158\n",
      "Best C: 1000.0 Best gamma: 1e-05 Fold test accuracy: 0.9380530973451328\n",
      "Average accuracy: 94.72597422760441 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = svm.SVC(gamma=0.01, C=10.)\n",
    "Cs = np.logspace(-1, 3, 9)\n",
    "Gs = np.logspace(-7, -0, 8)\n",
    "clf = GridSearchCV(estimator=clf, param_grid=dict(C=Cs, gamma=Gs), n_jobs=-1)\n",
    "\n",
    "score = []\n",
    "k_fold = KFold(n_splits=5)\n",
    "for train_indices, test_indices in k_fold.split(cancer.data):\n",
    "    clf.fit(cancer.data[train_indices], cancer.target[train_indices])\n",
    "    score.append(clf.score(cancer.data[test_indices], cancer.target[test_indices]))\n",
    "    print('Best C:', clf.best_estimator_.C,\n",
    "          'Best gamma:', clf.best_estimator_.gamma,\n",
    "          'Fold test accuracy:', score[-1])\n",
    "print('Average accuracy: {} %'.format(np.mean(score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'log(gamma)')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid results for last fold\n",
    "scores = clf.cv_results_['mean_test_score'].reshape(len(Cs), len(Gs))\n",
    "extent = np.log10([Gs[0], Gs[-1], Cs[0], Cs[-1]])\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "im = plt.imshow(scores, extent=extent, origin='lower')\n",
    "plt.colorbar(im)\n",
    "plt.contour(np.log10(Gs), np.log10(Cs), scores)\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('log(gamma)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to use a different classifier. For example, we will now try a Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9508458646616542\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "#clf = tree.DecisionTreeClassifier(criterion = \"entropy\")\n",
    "clf = RandomForestClassifier(n_estimators = 2000,max_depth = 4)\n",
    "score_tree = cross_val_score(clf, cancer.data, cancer.target, cv=k_fold, n_jobs=-1)\n",
    "print('Average accuracy:', np.mean(score_tree))\n",
    "\n",
    "# Now fit the tree\n",
    " # TODO: insert code here\n",
    "clf.fit(cancer.data[:-50], cancer.target[:-50])    \n",
    "y_pred = clf.predict(cancer.data[-50:])\n",
    "cnf_matrix = confusion_matrix(cancer.target[-50:], y_pred)\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the new confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: insert code here\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(len(set(cancer.target[-50:]))), normalize = False,\n",
    "                      title='Confusion matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what are the most important features from our dataset according to the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 27 23  7 20  2  6  3  0 13 26 21 25  1 12 10 24  5 28 29 16  4 17 19\n",
      " 11 15  9  8 18 14]\n",
      "Feature ranking:\n",
      "1. worst perimeter (0.132116)\n",
      "2. worst concave points (0.129088)\n",
      "3. worst area (0.117239)\n",
      "4. mean concave points (0.109951)\n",
      "5. worst radius (0.103447)\n",
      "6. mean perimeter (0.052507)\n",
      "7. mean concavity (0.047959)\n",
      "8. mean area (0.047930)\n",
      "9. mean radius (0.041320)\n",
      "10. area error (0.038253)\n",
      "11. worst concavity (0.032666)\n",
      "12. worst texture (0.017993)\n",
      "13. worst compactness (0.016625)\n",
      "14. mean texture (0.014810)\n",
      "15. perimeter error (0.014669)\n",
      "16. radius error (0.013385)\n",
      "17. worst smoothness (0.012475)\n",
      "18. mean compactness (0.010142)\n",
      "19. worst symmetry (0.009342)\n",
      "20. worst fractal dimension (0.005621)\n",
      "21. concavity error (0.005099)\n",
      "22. mean smoothness (0.004390)\n",
      "23. concave points error (0.003822)\n",
      "24. fractal dimension error (0.003671)\n",
      "25. texture error (0.003188)\n",
      "26. compactness error (0.002764)\n",
      "27. mean fractal dimension (0.002602)\n",
      "28. mean symmetry (0.002516)\n",
      "29. symmetry error (0.002319)\n",
      "30. smoothness error (0.002090)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.42100963284617215)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(indices)\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_features):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, cancer.feature_names[indices[f]],  importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "fig = plt.figure()\n",
    "plt.title(\"Feature importances\")  # just the top 10 features\n",
    "num_feat_to_plot = 10\n",
    "plt.bar(range(num_feat_to_plot), importances[indices[:num_feat_to_plot]],\n",
    "       color=\"r\", yerr=std[indices[:num_feat_to_plot]], align=\"center\")\n",
    "plt.xticks(range(num_feat_to_plot), np.array(cancer.feature_names)[indices[:num_feat_to_plot]])\n",
    "plt.xlim([-1, num_feat_to_plot])\n",
    "fig.set_size_inches(15,8)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,None])\n",
    "\n",
    "#plt.savefig(\"importances.png\",bbox_inches='tight')\n",
    "#plt.savefig(\"importances.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the distributions of values of the top 5 features. Are there any relationships between them? You can use functions from seaborn such as distplot or jointplot to look at this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you figure out whether your data should be standardised? If so, play with different methods from the sklearn library.\n",
    "You can get some ideas from here: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "Make sure your data still looks OK before attempting to re-train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                0.605518   ...         0.141525         0.668310    0.450698   \n",
       "1                0.141323   ...         0.303571         0.539818    0.435214   \n",
       "2                0.211247   ...         0.360075         0.508442    0.374508   \n",
       "3                1.000000   ...         0.385928         0.241347    0.094008   \n",
       "4                0.186816   ...         0.123934         0.506948    0.341575   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.598462                 0.418864     0.0  \n",
       "1        0.233590                 0.222878     0.0  \n",
       "2        0.403706                 0.213433     0.0  \n",
       "3        1.000000                 0.773711     0.0  \n",
       "4        0.157500                 0.142595     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "cols = df.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(df)\n",
    "normalised = pd.DataFrame(X_train_minmax)\n",
    "\n",
    "normalised.columns = cols\n",
    "normalised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've standardised your data (if required), try to fit an SVM classifier again. Is the performance affected by this processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9087253532060238\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=1e-05, C=1000)\n",
    "\n",
    "\n",
    "X = normalised.drop(['target'],axis=1)\n",
    "y = normalised['target']\n",
    "score_tree = cross_val_score(clf, X, y, cv=k_fold, n_jobs=-1)\n",
    "print('Average accuracy:', np.mean(score_tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
